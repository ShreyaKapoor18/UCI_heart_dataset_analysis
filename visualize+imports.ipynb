{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "import os \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    csv_path= os.path.join(path,filename) \n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_features(list_features,labels, testsize): \n",
    "    l1 = [3,4,7,8]\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    #print ('accuracy','precision ','recall ', '   f1')\n",
    "    i = 1\n",
    "    for feature in list_features : \n",
    "        #print ('feature',i )\n",
    "        i+=1\n",
    "        acc1 = []\n",
    "        prec1 = []\n",
    "        rec1 = []\n",
    "        f1_1 = []\n",
    "        for k in [3,4,7,8]: \n",
    "            features_train, features_test, labels_train, labels_test = train_test_split(feature, labels, test_size=testsize,random_state = 42)\n",
    "            #print ('k=',k)\n",
    "            classifier = KNeighborsClassifier(n_neighbors = k )\n",
    "            features_train = scaler.fit_transform(features_train)\n",
    "            features_test = scaler.transform(features_test)\n",
    "            # Fit data\n",
    "            classifier.fit (features_train, labels_train)\n",
    "\n",
    "            pred = classifier.predict(features_test)\n",
    "            accuracy = accuracy_score(labels_test, pred)\n",
    "            precision = precision_score (labels_test, pred)\n",
    "            recall = recall_score(labels_test, pred)\n",
    "            f1s = f1_score(pred,labels_test)\n",
    "            acc1.append(accuracy)\n",
    "            prec1.append(precision)\n",
    "            rec1.append(recall)\n",
    "            f1_1.append(f1s)\n",
    "            #print ('{:.2f}'.format(accuracy),\"   \", '{:.2f}'.format(precision),\" \",'{:10.2f}'.format(recall), '{:10.2f}'.format(f1s))\n",
    "        acc.append(acc1)\n",
    "        prec.append(prec1)\n",
    "        rec.append(rec1)\n",
    "        f1.append(f1_1)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(list_feature,labels, testsize, y_lim):\n",
    "    acc,prec,rec,f1 = evaluate_features(list_feature, labels, testsize)\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4, figsize= (20,5))\n",
    "    l1 =[3,4,7,8]\n",
    "    for (a,b) in [(ax1,acc),(ax2,prec),(ax3,rec),(ax4,f1)]: \n",
    "            for i in range(len(b[0])): \n",
    "                #print (l1,b[:][i])\n",
    "                a.scatter(l1,b[:][i])\n",
    "                a.set_ylim(y_lim[0],y_lim[1])\n",
    "                a.set_yticks(np.arange(y_lim[0], y_lim[1], 0.05))\n",
    "                a.plot(l1,b[i])\n",
    "            a.legend(['features','features2','features3','features4'])\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax2.set_ylabel('precision')\n",
    "    ax3.set_ylabel('recall')\n",
    "    ax4.set_ylabel('f1')\n",
    "    for a in [ax1,ax2,ax3,ax4]: \n",
    "        a.set_xlabel('n_neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm(list_features,labels, testsize):\n",
    "    i = 1\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1s = []\n",
    "    for features in list_features: \n",
    "        acc1 = []\n",
    "        prec1 = []\n",
    "        rec1 = []\n",
    "        f1s1 = []\n",
    "        #print ('features',i)\n",
    "        i+=1\n",
    "        \n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=testsize,random_state = 42)\n",
    "        kernels = ['linear', 'rbf', 'poly']\n",
    "        #print ('         accuracy ','precision  ' ,'recall ' ,'   f1s ')\n",
    "        for kname in kernels: \n",
    "            #print ('{:^7}'.format(kname), end = ':')\n",
    "\n",
    "            classifier = SVC(C=1, kernel = kname)\n",
    "            features_train = scaler.fit_transform(features_train)\n",
    "            features_test = scaler.transform(features_test)\n",
    "                        # Fit data\n",
    "            classifier.fit (features_train, labels_train)\n",
    "\n",
    "            pred = classifier.predict(features_test)\n",
    "            acc1.append(accuracy_score(labels_test, pred))\n",
    "            prec1.append(precision_score (labels_test, pred))  \n",
    "            rec1.append(recall_score(labels_test,pred))\n",
    "            f1s1.append(f1_score(pred,labels_test))\n",
    "            #print ( '{:^10.3f}'.format(accuracy_score(labels_test, pred)), end = '|', flush = True)\n",
    "            #print ('{:^10.3f}'.format(precision_score (labels_test, pred)), end = '|', flush = True)\n",
    "            #print ( '{:^10.3f}'.format(recall_score(labels_test, pred)), end = '|', flush = True)\n",
    "            #print ('{:^10.3f}'.format(f1_score(pred,labels_test)))\n",
    "        acc.append(acc1)\n",
    "        prec.append(prec1)\n",
    "        rec.append(rec1)\n",
    "        f1s.append(f1s1)\n",
    "    return acc, prec,rec,f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_knn(list_features,labels, testsize):\n",
    "    i = 0\n",
    "    fig, ax = plt.subplots(len(list_features),3, figsize= (15,10))\n",
    "    ax = ax.ravel()\n",
    "    print ('Confusion matrix, with normalization')\n",
    "    for features in list_features: \n",
    "        #print ('features ',i)\n",
    "        \n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=testsize,random_state = 42)\n",
    " \n",
    "        #print ('         accuracy ','precision  ' ,'recall ' ,'   f1s ')\n",
    "        for k in [3,4,7]: \n",
    "            #print ('{:^7}'.format(kname), end = ':')\n",
    "            classifier = KNeighborsClassifier(n_neighbors = k )\n",
    "            features_train = scaler.fit_transform(features_train)\n",
    "            features_test = scaler.transform(features_test)\n",
    "            # Fit data\n",
    "            classifier.fit (features_train, labels_train)\n",
    "            pred = classifier.predict(features_test)\n",
    "            \n",
    "            title = str(k) + ' features '+ str((i//3)+1)\n",
    "            normalize = True\n",
    "           \n",
    "            #This function prints and plots the confusion matrix.\n",
    "            #Normalization can be applied by setting `normalize=True`.\n",
    "            \n",
    "            \"\"\"if not title:\n",
    "                if normalize:\n",
    "                    title = 'Normalized confusion matrix'\n",
    "                else:\n",
    "                    title = \"\"\"\n",
    "            \n",
    "\n",
    "            # Compute confusion matrix\n",
    "            cm = confusion_matrix(labels_test, pred)\n",
    "            classes = unique_labels(labels_test,pred)\n",
    "            # Only use the labels that appear in the data\n",
    "            if normalize:\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                #print(\"Normalized confusion matrix\")\n",
    "            #else:\n",
    "                #print('Confusion matrix, without normalization')\n",
    "\n",
    "            #print(cm)\n",
    "            im = ax[i].imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "            ax[i].figure.colorbar(im, ax=ax[i])\n",
    "           \n",
    "            # We want to show all ticks...\n",
    "            ax[i].set(xticks=np.arange(cm.shape[1]),\n",
    "                   yticks=np.arange(cm.shape[0]),\n",
    "                   # ... and label them with the respective list entries\n",
    "                   xticklabels=classes, yticklabels=classes,\n",
    "                   title=title,\n",
    "                   ylabel='True label',\n",
    "                   xlabel='Predicted label')\n",
    "\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax[i].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "\n",
    "            # Loop over data dimensions and create text annotations.\n",
    "            fmt = '.2f' if normalize else 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for l in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    ax[i].text(j, l, format(cm[l, j], fmt),\n",
    "                            ha=\"center\", va=\"center\",\n",
    "                            color=\"white\" if cm[l, j] > thresh else \"black\")\n",
    "            fig.tight_layout()\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_svm(list_features,labels, testsize):\n",
    "    i = 0\n",
    "    fig, ax = plt.subplots(len(list_features),3, figsize= (15,10))\n",
    "    ax = ax.ravel()\n",
    "    print ('Confusion matrix, with normalization')\n",
    "    for features in list_features: \n",
    "        #print ('features ',i)\n",
    "        \n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=testsize,random_state = 42)\n",
    "        kernels = ['linear', 'rbf', 'poly']\n",
    "        #print ('         accuracy ','precision  ' ,'recall ' ,'   f1s ')\n",
    "        for kname in kernels: \n",
    "            #print ('{:^7}'.format(kname), end = ':')\n",
    "\n",
    "            classifier = SVC(C=1, kernel = kname)\n",
    "            features_train = scaler.fit_transform(features_train)\n",
    "            features_test = scaler.transform(features_test)\n",
    "            classifier.fit (features_train, labels_train)\n",
    "            pred = classifier.predict(features_test)\n",
    "            \n",
    "            \n",
    "            title = kname + ' features '+ str((i//3)+1)\n",
    "            normalize = True\n",
    "           \n",
    "            #This function prints and plots the confusion matrix.\n",
    "            #Normalization can be applied by setting `normalize=True`.\n",
    "            \n",
    "            \"\"\"if not title:\n",
    "                if normalize:\n",
    "                    title = 'Normalized confusion matrix'\n",
    "                else:\n",
    "                    title = \"\"\"\n",
    "            \n",
    "\n",
    "            # Compute confusion matrix\n",
    "            cm = confusion_matrix(labels_test, pred)\n",
    "            classes = unique_labels(labels_test,pred)\n",
    "            # Only use the labels that appear in the data\n",
    "            if normalize:\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                #print(\"Normalized confusion matrix\")\n",
    "            #else:\n",
    "                #print('Confusion matrix, without normalization')\n",
    "\n",
    "            #print(cm)\n",
    "            im = ax[i].imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "            ax[i].figure.colorbar(im, ax=ax[i])\n",
    "           \n",
    "            # We want to show all ticks...\n",
    "            ax[i].set(xticks=np.arange(cm.shape[1]),\n",
    "                   yticks=np.arange(cm.shape[0]),\n",
    "                   # ... and label them with the respective list entries\n",
    "                   xticklabels=classes, yticklabels=classes,\n",
    "                   title=title,\n",
    "                   ylabel='True label',\n",
    "                   xlabel='Predicted label')\n",
    "\n",
    "            # Rotate the tick labels and set their alignment.\n",
    "            plt.setp(ax[i].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "\n",
    "            # Loop over data dimensions and create text annotations.\n",
    "            fmt = '.2f' if normalize else 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for l in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    ax[i].text(j, l, format(cm[l, j], fmt),\n",
    "                            ha=\"center\", va=\"center\",\n",
    "                            color=\"white\" if cm[l, j] > thresh else \"black\")\n",
    "            fig.tight_layout()\n",
    "            i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_svm(list_feature,labels, testsize, y_lim): \n",
    "    acc,prec,rec,f1 = get_svm(list_feature, labels, testsize)\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4, figsize= (20,5))\n",
    "    for (a,b) in [(ax1,acc),(ax2,prec),(ax3,rec),(ax4,f1)]: \n",
    "        #print (b)\n",
    "        #c = ['red', 'green','blue','yellow']\n",
    "        #print (len(b))\n",
    "        for i in range(len(b)): \n",
    "            #print (b[:][i])\n",
    "            a.set_ylim(y_lim[0],y_lim[1])\n",
    "            a.set_yticks(np.arange(y_lim[0], y_lim[1], 0.05))\n",
    "            a.plot(['linear','rbf','poly'], b[:][i])\n",
    "            a.scatter(['linear','rbf','poly'], b[:][i])\n",
    "            \n",
    "        a.legend(['features','features2','features3','features4'])\n",
    "        #print ('\\n')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax2.set_ylabel('precision')\n",
    "    ax3.set_ylabel('recall')\n",
    "    ax4.set_ylabel('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl_draw(dataset): \n",
    "# with the dataframe correlation function\n",
    "    corr = dataset.corr()\n",
    "    fig, ax = plt.subplots(figsize = (20, 20))\n",
    "    # Colours the rectangles by correlation value\n",
    "    d = ax.matshow(corr,cmap='jet')\n",
    "    # Draws x ticks labels\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    # Draws y ticks labels\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    # Shows figure\n",
    "    fig.colorbar(d)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
